{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vine-Tweets Dataset\n",
    "\n",
    "This Notebook describes how to download and work with the [Vine-Tweets Dataset](https://archive.org/details/vine-tweets) which was generated as part of an effort by the [ArchiveTeam](https://archiveteam.org/) to archive videos from the [Vine] social media platform after they announced it was sunsetting the service. Part of this effort involved watching Twitter for tweets mentioning Vine URLs. This data collection from Twitter was performed by [a bot](https://gist.github.com/edsu/88bb252cae8731a17a503d401bba48c4) for a little over a year, during which it collected 127,655,208 tweets that mentioned a vine.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First you'll need to have Python3 to use this notebook. Once you've got that installed here are the steps you'll need to follow to get this notebook up and running:\n",
    "    \n",
    "    % git checkout https://github.com/edsu/vine-tweets-notebook\n",
    "    % cd vine-tweets-notebook\n",
    "    % pip3 install pipenv\n",
    "    % pipenv install\n",
    "    % jupyter notebook Vine-Tweets Dataset.ipynb\n",
    "\n",
    "The next step is to download the [Vine-Tweets Dataset](https://archive.org/details/vine-tweets) from the Internet Archive. Choose the gzip version of all 13 files. It'll take a bit of time to download as its 1.6G. Once it has finished unzip it into the same directory where you have this Jupyter notebook. \n",
    "\n",
    "    % wget https://archive.org/compress/vine-tweets/formats=GZIP&file=/vine-tweets.zip\n",
    "    % unzip vine-tweets.zip\n",
    "    % cd vine-tweets\n",
    "    \n",
    "## Data Prep\n",
    "    \n",
    "To make it easier to process, unarchive and uncompress the files:\n",
    "\n",
    "    % for f in `ls *.tar.gz`; do tar xvfz $f; done\n",
    "    \n",
    "Now your vine-tweets directory should have 13 subdirectories named in a pattern of `YYYYMM` for the year and month that they were collected. Each subdirectory contains a timestamped filename, each of which contains lines of *(tweet id, vine url) tuples, e.g.\n",
    "\n",
    "    801582593330200577 https://vine.co/v/i3qmOAjOLzd\n",
    "    801582592747257860 https://vine.co/v/iz635MvhWFF\n",
    "    801582592634060801 https://vine.co/v/5t0I0hD5tUE\n",
    "    801582592315314176 https://vine.co/v/i3X3mOzWxpY\n",
    "    801582592256577536 https://vine.co/v/eYUgJWQlmYm\n",
    "    801582592235601921 https://vine.co/v/eJAvrYXxv2z\n",
    "    801582592143204352 https://vine.co/v/eU07l1EJjjJ\n",
    "    801582591740559360 https://vine.co/v/5t2dQ5qY2hZ\n",
    "    801582591488966658 https://vine.co/v/5vdjJbVDeqL\n",
    "    801582591065341952 https://vine.co/v/5t37Wd9DQFm\n",
    "    \n",
    "The tweet id can be resolved to a tweet by interpolated it into a URL like this: `https://twitter.com/i/status/{tweet-id}, e.g. https://twitter.com/i/status/801582591065341952.\n",
    "\n",
    "## Summarize\n",
    "\n",
    "To process these files its useful to create a generator function that will simply return the list of filenames to process\n",
    "\n",
    "[Vine]: https://en.wikipedia.org/wiki/Vine_(service)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def get_filenames():\n",
    "    yield from sorted(glob(\"vine-tweets/*/*.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vine-tweets/201611/20161109165738.txt',\n",
       " 'vine-tweets/201611/20161109175807.txt',\n",
       " 'vine-tweets/201611/20161109185807.txt',\n",
       " 'vine-tweets/201611/20161109195810.txt',\n",
       " 'vine-tweets/201611/20161109205841.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_filenames())[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, and here is a simple function that returns the date for a given filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-11-10'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_date(filename):\n",
    "    return '%s-%s-%s' % re.search('/(\\d{4})(\\d{2})(\\d{2})', filename).groups()\n",
    "\n",
    "get_date('vine-tweets/201611/20161110020111.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with the data it's useful to take one pass through all of it and generate some counts of vines and tweets by day. To save time this is only performed if the `vine-tweets.csv` is not already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "if not os.path.isfile('vine-tweets.csv'):\n",
    "\n",
    "    tweets_per_day = Counter()\n",
    "    vines_per_day = Counter()\n",
    "    vine_urls = Counter()\n",
    "\n",
    "    current_date = None\n",
    "\n",
    "    def save(date, vine_urls):\n",
    "        tweets = tweets_per_day[date]\n",
    "        vines = len(vine_urls.keys())\n",
    "        vines_per_day[date] = vines\n",
    "    \n",
    "        print(\"{} - {:,} vines - {:,} tweets - {:0.2f}\".format(\n",
    "            date, \n",
    "            vines,\n",
    "            tweets,\n",
    "            vines / tweets\n",
    "        ))\n",
    "        with open(\"vines/%s.csv\" % current_date, \"w\") as output:\n",
    "            for url, count in vine_urls.items():\n",
    "                output.write(\"%s,%s\\n\" % (url, count))\n",
    "    \n",
    "    for filename in get_filenames():\n",
    "        date = get_date(filename)\n",
    "    \n",
    "        if current_date is None:\n",
    "            current_date = date\n",
    "        \n",
    "        if date != current_date:\n",
    "            save(current_date, vine_urls)\n",
    "            vine_urls = Counter()\n",
    "            current_date = date        \n",
    "        \n",
    "        for line in open(filename):\n",
    "            try:\n",
    "                tweet_id, url = line.strip().split(' ')\n",
    "                tweets_per_day[date] += 1\n",
    "                vine_urls[url] += 1\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "    save(date, vine_urls)\n",
    "\n",
    "    with open(\"vine-tweets.csv\", \"w\") as output:\n",
    "        output.write(\"date,vines,tweets\\n\")\n",
    "        for date in vines_per_day.keys():\n",
    "            output.write(\"{},{},{}\\n\".format(date, vines_per_day[date], tweets_per_day[date]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
